+++
date = '2026-02-09T10:19:07+08:00'
draft = false
title = 'CUDA Programming Guide Notes 1'
tags = ['CUDA']
toc = true
series = ["CUDA Programming Guide Notes"]
+++

# CUDA Programming Guide Notes 1

> 原文地址：https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/programming-model.html

## CUDA编程模型

### 1. 线程块和网格

当一个程序启动kernel时，涉及了许多线程，经常是数百万的线程。这些线程被组织到Blocks里面。这些block自然就被称为线程块。线程块又被组织进Grid（网格）里面。Grid里面所有的线程块有一样的大小和维度。

这里补充一张图片，图3

线程块和网格可以是 1 维、2 维或 3 维的。这些维度可以简化将单个线程映射到工作单元或数据项的过程。

当启动核函数时，需要使用特定的执行配置（execution configuration）来指定网格和线程块的维度。执行配置还可以包括一些可选参数，如 Cluster 大小、Stream 以及 SM 配置设置，这些将在后续章节中介绍。

使用内置变量，每个执行核函数的线程都可以确定：

- 自身在所属线程块中的位置
- 所属线程块在网格中的位置
- 线程块的维度以及启动核函数时所使用的网格的维度

这使得每个线程在所有运行该核函数的线程中拥有唯一的标识。这个标识常用于确定该线程负责处理哪些数据或执行哪些操作。

一个线程块中的所有线程都由单个 SM 执行。这使得线程块内的线程能够高效地相互通信和同步。线程块内的所有线程都可以访问片上共享内存（on-chip Shared Memory），可用于线程块内线程之间的信息交换。

一个网格可能由数百万个线程块组成，而执行该网格的 GPU 可能只有数十个或数百个 SM（流式多处理器）。一个线程块的所有线程都由单个 SM 执行，并且在大多数情况下 [1]，在该 SM 上运行直到完成。线程块之间的调度没有保证，因此一个线程块不能依赖其他线程块的结果，因为那些线程块可能要等到当前线程块完成后才能被调度。图 4 展示了一个示例，说明网格中的线程块如何分配到 SM 上。

图4

CUDA 编程模型使得任意大小的网格都能够在任何规模的 GPU 上运行，无论该 GPU 只有一个 SM 还是拥有数千个 SM。为了实现这一点，CUDA 编程模型要求（除少数例外情况外）不同线程块中的线程之间不存在数据依赖关系。也就是说，一个线程不应该依赖于同一网格中不同线程块中某个线程的结果，也不应该与其同步。一个线程块内的所有线程同时在同一个 SM 上运行。网格内的不同线程块会被调度到可用的 SM 上，并且可以按任意顺序执行。简而言之，CUDA 编程模型要求线程块必须能够以任意顺序执行，无论是并行执行还是串行执行。

### 2. 线程块Clusters（集群、簇）

此外，计算能力为 9.0 及更高版本的 GPU 还支持一个可选的分组层级，称为簇（Clusters）。簇是一组线程块的集合，与线程块和网格类似，簇也可以按 1 维、2 维或 3 维进行布局。图 5 展示了一个组织成簇的线程块网格。指定簇不会改变网格的维度，也不会改变线程块在网格中的索引。

> 就是一些高版本的 CUDA 支持在一个网格当中，把线程块分了个组

指定簇（Clusters）会将相邻的线程块分组到簇中，并在簇层级提供一些额外的同步和通信机会。具体来说，一个簇中的所有线程块都在单个 GPC（Graphics Processing Cluster，图形处理簇）中执行。图 6 展示了当指定簇时，线程块如何被调度到 GPC 内的 SM 上。由于这些线程块是同时调度的，并且位于单个 GPC 内，因此不同线程块但位于同一个簇中的线程可以使用 Cooperative Groups 提供的软件接口相互通信和同步。簇中的线程可以访问该簇内所有线程块的共享内存，这被称为分布式共享内存（Distributed Shared Memory）。簇的最大尺寸取决于硬件，不同设备之间有所不同。

> 就是一个簇里面的线程块可以共享资源：共享内存、相互通信、可以同步

这里是图6

### 3. Warps和SIMT

在线程块内部，线程被组织成每组 32 个线程的单元，称为线程束（Warp）。线程束以单指令多线程（SIMT，Single-Instruction Multiple-Threads） 范式执行核函数代码。在 SIMT 模式下，线程束中的所有线程执行相同的核函数代码，但每个线程可以在代码中遵循不同的分支。也就是说，尽管程序的所有线程执行相同的代码，但线程不需要遵循相同的执行路径。

当线程被线程束执行时，它们会被分配一个线程束通道（Warp Lane）。线程束通道编号从 0 到 31，线程块中的线程按照《硬件多线程》章节详细说明的可预测方式分配到线程束中。

线程束中的所有线程同时执行相同的指令。如果线程束内的一些线程在执行中遵循某个控制流分支，而其他线程不遵循，那么不遵循该分支的线程将被屏蔽（masked off），而遵循该分支的线程继续执行。例如，如果某个条件判断仅对线程束中一半的线程为真，那么线程束的另一半将被屏蔽，而活跃的线程执行这些指令。图 7 展示了这种情况。当线程束中的不同线程遵循不同的代码路径时，这种情况有时被称为线程束分化（Warp Divergence）。由此可见，当线程束内的线程遵循相同的控制流路径时，GPU 的利用率最大化。

这里是图7

在 SIMT 模型中，线程束中的所有线程以锁步（lock step） 方式在核函数中推进。硬件执行可能有所不同。有关这种区别重要性的更多信息，请参见《独立线程执行》章节。不建议利用线程束执行如何实际映射到真实硬件的知识。CUDA 编程模型和 SIMT 指出，线程束中的所有线程一起在代码中推进。只要遵循编程模型，硬件可以以对程序透明的方式优化被屏蔽的通道。如果程序违反此模型，可能会导致未定义行为，这种行为在不同的 GPU 硬件上可能不同。

线程束执行的一个含义是，线程块最好指定线程总数为 32 的倍数。使用任意数量的线程是合法的，但当总数不是 32 的倍数时，线程块的最后一个线程束将在整个执行过程中有一些未使用的通道。这可能会导致该线程束的功能单元利用率和内存访问性能不佳。
